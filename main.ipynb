{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "from dnb_annual import *\n",
    "from variables import years, composites, region_map, region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script is used only once to generate the regional images for each year\n",
    "# country_polygons = gpd.read_file(\"geoBoundaries-UKR-ADM1.geojson\")\n",
    "\n",
    "# for year in years:\n",
    "#     dnb = dnb_annual(year, composites, country_polygons)\n",
    "#     dnb.load_all_data()\n",
    "#     dnb.save_rasters()\n",
    "#     dnb.load_rasters()\n",
    "#     dnb.build_regional_images()\n",
    "#     dnb.add_padding()\n",
    "#     dnb.save_regional_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script is used to clean gdp data\n",
    "\n",
    "# Inflation data\n",
    "# inflation = pd.read_excel(\"data/isc_reg.xls\", skiprows=2, header=1)\n",
    "# inflation = inflation.drop(columns=inflation.columns[0])\n",
    "# inflation = inflation.rename(columns={inflation.columns[-1]: \"region\"})\n",
    "# inflation = inflation[~inflation[\"region\"].isin([\"Ukraine\", \"oblasts\"])]\n",
    "# inflation = inflation.dropna()\n",
    "# inflation[\"region\"] = inflation[\"region\"].map(region_map)\n",
    "# inflation.columns = inflation.columns.astype(str)\n",
    "# inflation = inflation.melt(id_vars=\"region\", var_name=\"year\", value_name=\"inflation\")\n",
    "# inflation.to_csv(\"data/inflation.csv\", index=False)\n",
    "\n",
    "# GDP data\n",
    "# gdp = pd.read_excel(\"data/ukr_reg_gdp.xls\", skiprows=3, header=1)\n",
    "# gdp = gdp.drop(columns=gdp.columns[0])\n",
    "# gdp = gdp.iloc[:, np.r_[18:36, -1]]\n",
    "# gdp = gdp.rename(columns={gdp.columns[-1]: \"region\"})\n",
    "# gdp = gdp[~gdp[\"region\"].isin([\"Ukrane\", \"oblasts\"])]\n",
    "# gdp = gdp.dropna()\n",
    "# gdp[\"region\"] = gdp[\"region\"].map(region_map)\n",
    "# gdp[\"region\"] = gdp[\"region\"].fillna(\"Sevastopol\")\n",
    "# gdp.columns = gdp.columns.astype(str)\n",
    "# gdp = gdp.rename(columns={gdp.columns[i]: gdp.columns[i][:4] for i in range(18)})\n",
    "# gdp = gdp.melt(id_vars=\"region\", var_name=\"year\", value_name=\"real_gdp_change\")\n",
    "\n",
    "# # include only years from 2012 inclusive, exclude Sevastopol and the Autonomous Republic of Crimea\n",
    "# gdp = gdp[gdp[\"year\"].astype(int) >= 2012]\n",
    "# gdp = gdp[~gdp[\"region\"].isin([\"Sevastopol\", \"Autonomous Republic of Crimea\"])]\n",
    "\n",
    "# # set the value for the starting year to 100 (2012), NaN for the rest\n",
    "# gdp.loc[gdp[\"year\"] == \"2012\", \"real_gdp\"] = 100\n",
    "# gdp = gdp.sort_values(by=[\"region\", \"year\"])\n",
    "# gdp[\"real_gdp_change\"] = gdp[\"real_gdp_change\"] / 100\n",
    "\n",
    "# # reste the index\n",
    "# gdp = gdp.reset_index(drop=True)\n",
    "\n",
    "# # # calculate the real gdp\n",
    "# for i in range(1, gdp.shape[0]):\n",
    "\n",
    "#     # skip if the year is 2012\n",
    "#     if gdp.loc[gdp.index[i], \"year\"] == \"2012\":\n",
    "#         continue\n",
    "#     else:\n",
    "#         gdp.loc[gdp.index[i], \"real_gdp\"] = gdp.loc[gdp.index[i-1], \"real_gdp\"] * (gdp.loc[gdp.index[i], \"real_gdp_change\"])\n",
    "\n",
    "# # delete the real_gdp_change column\n",
    "# gdp = gdp.drop(columns=\"real_gdp_change\")\n",
    "\n",
    "# # get the nominal gdp\n",
    "# gdp_nominal = pd.read_excel(\"data/ukr_reg_gdp.xls\", skiprows=3, header=1)\n",
    "# gdp_nominal = gdp_nominal.iloc[:, np.r_[9, -1]]\n",
    "# gdp_nominal.columns = [\"gdp_nominal\", \"region\"]\n",
    "# gdp_nominal = gdp_nominal[~gdp_nominal[\"region\"].isin([\"Ukrane\", \"oblasts\"])]\n",
    "# gdp_nominal = gdp_nominal.dropna()\n",
    "# gdp_nominal[\"region\"] = gdp_nominal[\"region\"].map(region_map)\n",
    "# gdp_nominal[\"region\"] = gdp_nominal[\"region\"].fillna(\"Sevastopol\")\n",
    "\n",
    "# # merge nominal gdp to real gdp by region\n",
    "# gdp = gdp.merge(gdp_nominal, on=\"region\")\n",
    "\n",
    "# # multiple the real gdp by the nominal gdp\n",
    "# gdp[\"real_gdp\"] = gdp[\"real_gdp\"] * gdp[\"gdp_nominal\"]\n",
    "\n",
    "# # drop the nominal gdp column\n",
    "# gdp = gdp.drop(columns=\"gdp_nominal\")\n",
    "\n",
    "# # for the region column, change all spaces to _\n",
    "# gdp[\"region\"] = gdp[\"region\"].str.replace(\" \", \"_\")\n",
    "\n",
    "# # save the data\n",
    "# gdp.to_csv(\"data/clean_ukr_gdp.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare gdp data, Ukraine\n",
    "gdp_ukr = pd.read_excel(\"data/ukr_reg_gdp.xls\", skiprows=3, header=1)\n",
    "gdp_ukr = gdp_ukr.drop(columns=gdp_ukr.columns[0])\n",
    "gdp_ukr = gdp_ukr.iloc[:, np.r_[18:36, -1]]\n",
    "gdp_ukr = gdp_ukr.rename(columns={gdp_ukr.columns[-1]: \"region\"})\n",
    "gdp_ukr = gdp_ukr[~gdp_ukr[\"region\"].isin([\"Ukrane\", \"oblasts\"])]\n",
    "gdp_ukr = gdp_ukr.dropna()\n",
    "gdp_ukr[\"region\"] = gdp_ukr[\"region\"].map(region_map)\n",
    "gdp_ukr[\"region\"] = gdp_ukr[\"region\"].fillna(\"Sevastopol\")\n",
    "gdp_ukr.columns = gdp_ukr.columns.astype(str)\n",
    "gdp_ukr = gdp_ukr.rename(columns={gdp_ukr.columns[i]: gdp_ukr.columns[i][:4] for i in range(18)})\n",
    "gdp_ukr = gdp_ukr[~gdp_ukr[\"region\"].isin([\"Sevastopol\", \"Autonomous Republic of Crimea\"])]\n",
    "\n",
    "# select years from 2012 inclusive and the region column\n",
    "gdp_ukr = gdp_ukr[[gdp_ukr.columns[i] for i in range(18) if int(gdp_ukr.columns[i]) >= 2012] + [\"region\"]]\n",
    "\n",
    "# Poland\n",
    "gdp_pol = pd.read_excel(\"data/pol_reg_gdp.xlsx\", header=1, sheet_name=1)\n",
    "gdp_pol = gdp_pol.drop(columns=gdp_pol.columns[0])\n",
    "gdp_pol = gdp_pol.drop(0)\n",
    "gdp_pol = gdp_pol.rename(columns={gdp_pol.columns[0]: \"region\"})\n",
    "gdp_pol = gdp_pol.drop(columns=\"2022\")\n",
    "\n",
    "def clean_gdp_data(data):\n",
    "\n",
    "    # set the 2012 first column to 100\n",
    "    data[\"2012\"] = 100\n",
    "\n",
    "    # divide columns from 2013 to 2021 by 100\n",
    "    for year in range(2013, 2022):\n",
    "        data[str(year)] = data[str(year)] / 100\n",
    "\n",
    "    # calculate the real gdp\n",
    "    for i in range(2013, 2022):\n",
    "        data[str(i)] = data[str(i)] * data[str(i-1)]\n",
    "\n",
    "    # format to long\n",
    "    data = data.melt(id_vars=\"region\", var_name=\"year\", value_name=\"real_gdp\")\n",
    "    data[\"region\"] = data[\"region\"].str.replace(\" \", \"_\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "gdp_pol = clean_gdp_data(gdp_pol)\n",
    "gdp_ukr = clean_gdp_data(gdp_ukr)\n",
    "\n",
    "# save the data\n",
    "gdp_pol.to_csv(\"data/clean_pol_gdp.csv\", index=False)\n",
    "gdp_ukr.to_csv(\"data/clean_ukr_gdp.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Resizing, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# # Loading the MNIST dataset\n",
    "# from keras.datasets import mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean gdp data\n",
    "gdp = pd.read_csv(\"data/clean_ukr_gdp.csv\")\n",
    "\n",
    "# Initialise a three dimensional array to store the images with the shape (number of images, height, width, channels)\n",
    "X = np.zeros((len(gdp), 765, 1076, 2))\n",
    "y = np.zeros(len(gdp))\n",
    "\n",
    "# load the snow covered and snow free images, add them together and append to the list\n",
    "for i in range(len(gdp)):\n",
    "\n",
    "    # get year, region, and gdp\n",
    "    year = gdp[\"year\"][i]\n",
    "    region = gdp[\"region\"][i]\n",
    "    gdp_value = gdp[\"real_gdp\"][i]\n",
    "\n",
    "    # get the file name\n",
    "    file_name = f\"{year}_{region}.h5\"\n",
    "\n",
    "    # load the image\n",
    "    file_path = f\"data/annual_region_images/{file_name}\"\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as annual_region:\n",
    "        # nearnad_snow_cov = annual_region[\"NearNadir_Composite_Snow_Covered\"][:]\n",
    "        # nearnad_snow_free = annual_region[\"NearNadir_Composite_Snow_Free\"][:]\n",
    "        # offnad_snow_cov = annual_region[\"OffNadir_Composite_Snow_Covered\"][:]\n",
    "        # offnad_snow_free = annual_region[\"OffNadir_Composite_Snow_Free\"][:]\n",
    "        allangle_snow_cov = annual_region[\"AllAngle_Composite_Snow_Covered\"][:]\n",
    "        allangle_snow_free = annual_region[\"AllAngle_Composite_Snow_Free\"][:]\n",
    "\n",
    "        # add the two images together\n",
    "        # combined = snow_covered + snow_free\n",
    "\n",
    "    # add the gdp value to y\n",
    "    y[i] = gdp_value\n",
    "\n",
    "    # append both images as two channels to to X\n",
    "    X[i, :, :, 0] = allangle_snow_cov\n",
    "    X[i, :, :, 1] = allangle_snow_free\n",
    "    # X[i, :, :, 2] = offnad_snow_cov\n",
    "    # X[i, :, :, 3] = offnad_snow_free\n",
    "    # X[i, :, :, 4] = nearnad_snow_cov\n",
    "    # X[i, :, :, 5] = nearnad_snow_free\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# Normalise the images\n",
    "maximum = X.max()\n",
    "X = X / maximum\n",
    "\n",
    "# standardise gdp values\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "y = (y - y_mean) / y_std\n",
    "\n",
    "# print(y.mean())\n",
    "# print(maximum)\n",
    "\n",
    "# change the format to a float16\n",
    "X = X.astype(np.float16)\n",
    "y = y.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 80% of the data for training, choose randomly\n",
    "# X is the images, y is the gdp\n",
    "train_size = int(0.8 * len(gdp))\n",
    "test_size = len(gdp) - train_size\n",
    "\n",
    "# select randomly train_size numbers from 0 to len(gdp)\n",
    "train_indices = np.random.choice(len(gdp), train_size, replace=False)\n",
    "test_indices = np.setdiff1d(np.arange(len(gdp)), train_indices)\n",
    "\n",
    "# get the train data\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "# get the test data\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Resizing the images\n",
    "model.add(Resizing(300, 440, input_shape=(765, 1076, 2)))\n",
    "# Start with Convolutional layers\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  # Additional Conv layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))  # Additional Conv layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Flatten the results to feed into a dense layer\n",
    "model.add(Flatten())\n",
    "# Add dense layers (hidden layers)\n",
    "model.add(Dense(128, activation='relu'))  # Upscaled dense layer\n",
    "model.add(Dense(64, activation='relu'))   # Additional dense layer\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Resizing the images\n",
    "model.add(Resizing(300, 440, input_shape=(765, 1076, 2)))\n",
    "\n",
    "# Start with Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))  # Increased number of filters\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  # Increased number of filters\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))  # Increased number of filters\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))  # Increased number of filters\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the results to feed into a dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers (hidden layers)\n",
    "model.add(Dense(256, activation='relu'))  # Increased the number of neurons\n",
    "model.add(Dense(128, activation='relu'))  # Increased the number of neurons\n",
    "model.add(Dense(64, activation='relu'))   # Kept as is for detailed feature extraction\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 765, 1076, 4)\n",
      "0.0731\n"
     ]
    }
   ],
   "source": [
    "# check the size of X_train and y_train\n",
    "print(X_train.shape)\n",
    "print(X_train[1, :, :, 0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5/5 [==============================] - 12s 1s/step - loss: 1.2092 - mae: 0.6541 - val_loss: 0.6929 - val_mae: 0.4991\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 5s 1s/step - loss: 1.2174 - mae: 0.6176 - val_loss: 0.7056 - val_mae: 0.5114\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2105 - mae: 0.6277 - val_loss: 0.7263 - val_mae: 0.5304\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 4s 904ms/step - loss: 1.1566 - mae: 0.6187 - val_loss: 0.9748 - val_mae: 0.7484\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 4s 875ms/step - loss: 1.1084 - mae: 0.6428 - val_loss: 0.7364 - val_mae: 0.5270\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 4s 826ms/step - loss: 0.9653 - mae: 0.5858 - val_loss: 0.6319 - val_mae: 0.5539\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 4s 844ms/step - loss: 0.6955 - mae: 0.5298 - val_loss: 0.5679 - val_mae: 0.5229\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.7927 - mae: 0.5148 - val_loss: 0.5985 - val_mae: 0.5335\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 4s 851ms/step - loss: 0.6260 - mae: 0.4469 - val_loss: 0.5241 - val_mae: 0.4795\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.5635 - mae: 0.4621 - val_loss: 0.6669 - val_mae: 0.5458\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.5145 - mae: 0.4655 - val_loss: 0.4814 - val_mae: 0.4440\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 4s 818ms/step - loss: 0.4256 - mae: 0.3851 - val_loss: 0.5210 - val_mae: 0.4619\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.3751 - mae: 0.3834 - val_loss: 0.7211 - val_mae: 0.4847\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.3715 - mae: 0.3819 - val_loss: 0.5598 - val_mae: 0.4481\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 4s 831ms/step - loss: 0.3184 - mae: 0.3569 - val_loss: 0.6222 - val_mae: 0.4115\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.2599 - mae: 0.3196 - val_loss: 0.5864 - val_mae: 0.3944\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.2244 - mae: 0.2952 - val_loss: 0.6369 - val_mae: 0.5019\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.2405 - mae: 0.3059 - val_loss: 0.5648 - val_mae: 0.4546\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.3492 - mae: 0.3346 - val_loss: 0.5545 - val_mae: 0.4053\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.2431 - mae: 0.3010 - val_loss: 0.4114 - val_mae: 0.3901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1af00012f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)  # Assuming you have a validation split of 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 185ms/step - loss: 0.2886 - mae: 0.3669\n",
      "Test MAE: 0.36693692207336426\n",
      "Test Loss: 0.2886132001876831\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate your model on the testing data\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print('Test MAE:', test_mae) # mean absolute error\n",
    "print('Test Loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 231ms/step\n",
      "109.363976\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test).flatten()\n",
    "\n",
    "# print the mean absolute percentage error\n",
    "print(np.mean(100*np.abs((y_test - y_hat) / y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 56ms/step\n",
      "0.10076753842329474\n",
      "36.946041487261475\n"
     ]
    }
   ],
   "source": [
    "# get the predictions from X_test\n",
    "y_hat = model.predict(X_test).flatten()\n",
    "\n",
    "# convert the predictions back to the original scale\n",
    "# y_hat = y_hat * y_std + y_mean\n",
    "# y_test = y_test * y_std + y_mean\n",
    "\n",
    "# compute the mae\n",
    "mae = np.mean(np.abs(y_test - y_hat))\n",
    "print(mae)\n",
    "\n",
    "# compute the mean percentage error\n",
    "percentage_error = np.mean(100*np.abs((y_test - y_hat) / y_test))\n",
    "print(percentage_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "# load clean gdp data\n",
    "gdp = pd.read_csv(\"data/clean_gdp.csv\")\n",
    "\n",
    "# Initialise a three dimensional array to store the images with the shape (number of images, height, width, channels)\n",
    "X = np.zeros((len(gdp), 765, 1076, 4))\n",
    "y = np.zeros(len(gdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tabular data\n",
    "data = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "\n",
    "# turn the region column into a categorical variable using one hot encoding\n",
    "data = pd.get_dummies(data, columns=[\"region\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'gdp', 'nearnad_snow_cov_1', 'nearnad_snow_cov_2',\n",
       "       'nearnad_snow_cov_3', 'nearnad_snow_cov_4', 'nearnad_snow_cov_5',\n",
       "       'nearnad_snow_cov_6', 'nearnad_snow_cov_7', 'nearnad_snow_cov_8',\n",
       "       'nearnad_snow_cov_9', 'nearnad_snow_cov_10', 'nearnad_snow_free_1',\n",
       "       'nearnad_snow_free_2', 'nearnad_snow_free_3', 'nearnad_snow_free_4',\n",
       "       'nearnad_snow_free_5', 'nearnad_snow_free_6', 'nearnad_snow_free_7',\n",
       "       'nearnad_snow_free_8', 'nearnad_snow_free_9', 'nearnad_snow_free_10',\n",
       "       'offnad_snow_cov_1', 'offnad_snow_cov_2', 'offnad_snow_cov_3',\n",
       "       'offnad_snow_cov_4', 'offnad_snow_cov_5', 'offnad_snow_cov_6',\n",
       "       'offnad_snow_cov_7', 'offnad_snow_cov_8', 'offnad_snow_cov_9',\n",
       "       'offnad_snow_cov_10', 'offnad_snow_free_1', 'offnad_snow_free_2',\n",
       "       'offnad_snow_free_3', 'offnad_snow_free_4', 'offnad_snow_free_5',\n",
       "       'offnad_snow_free_6', 'offnad_snow_free_7', 'offnad_snow_free_8',\n",
       "       'offnad_snow_free_9', 'offnad_snow_free_10', 'allangle_snow_cov_1',\n",
       "       'allangle_snow_cov_2', 'allangle_snow_cov_3', 'allangle_snow_cov_4',\n",
       "       'allangle_snow_cov_5', 'allangle_snow_cov_6', 'allangle_snow_cov_7',\n",
       "       'allangle_snow_cov_8', 'allangle_snow_cov_9', 'allangle_snow_cov_10',\n",
       "       'allangle_snow_free_1', 'allangle_snow_free_2', 'allangle_snow_free_3',\n",
       "       'allangle_snow_free_4', 'allangle_snow_free_5', 'allangle_snow_free_6',\n",
       "       'allangle_snow_free_7', 'allangle_snow_free_8', 'allangle_snow_free_9',\n",
       "       'allangle_snow_free_10', 'region_Cherkasy_Oblast',\n",
       "       'region_Chernihiv_Oblast', 'region_Chernivtsi_Oblast',\n",
       "       'region_Dnipropetrovsk_Oblast', 'region_Donetsk_Oblast',\n",
       "       'region_Ivano-Frankivsk_Oblast', 'region_Kharkiv_Oblast',\n",
       "       'region_Kherson_Oblast', 'region_Khmelnytskyi_Oblast',\n",
       "       'region_Kirovohrad_Oblast', 'region_Kyiv', 'region_Kyiv_Oblast',\n",
       "       'region_Luhansk_Oblast', 'region_Lviv_Oblast', 'region_Mykolaiv_Oblast',\n",
       "       'region_Odessa_Oblast', 'region_Poltava_Oblast', 'region_Rivne_Oblast',\n",
       "       'region_Sumy_Oblast', 'region_Ternopil_Oblast',\n",
       "       'region_Vinnytsia_Oblast', 'region_Volyn_Oblast',\n",
       "       'region_Zakarpattia_Oblast', 'region_Zaporizhia_Oblast',\n",
       "       'region_Zhytomyr_Oblast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# drop year and gdp columns\n",
    "X = data.drop(columns=[\"year\", \"gdp\"])\n",
    "y = data[\"gdp\"]\n",
    "\n",
    "# standardise gdp\n",
    "# y_mean = y.mean()\n",
    "# y_std = y.std()\n",
    "# y = (y - y_mean) / y_std\n",
    "\n",
    "# take randomly 80% of the data for training\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "train_indices = np.random.choice(len(data), train_size, replace=False)\n",
    "test_indices = np.setdiff1d(np.arange(len(data)), train_indices)\n",
    "\n",
    "X_train = X.iloc[train_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "X_test = X.iloc[test_indices]\n",
    "y_test = y.iloc[test_indices]\n",
    "\n",
    "# train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get the predictions\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# compute the mae\n",
    "mae = np.mean(np.abs(y_test - y_hat))\n",
    "\n",
    "# compute the mean percentage error\n",
    "percentage_error = np.mean(100*np.abs((y_test - y_hat) / y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.596800568521989\n",
      "8.205373678630673\n"
     ]
    }
   ],
   "source": [
    "print(mae)\n",
    "print(percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.587519029167304\n",
      "13.155784903890575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/1922239168.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  model.fit(X_train, y_train)\n",
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5351.197506294976, tolerance: 6.679875229241091\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# fit a lasso regression model \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get the predictions\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# compute the mae\n",
    "mae = np.mean(np.abs(y_test - y_hat))\n",
    "\n",
    "# compute the mean percentage error\n",
    "percentage_error = np.mean(100*np.abs((y_test - y_hat) / y_test))\n",
    "\n",
    "print(mae)\n",
    "print(percentage_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.108772929030119\n",
      "9.519860976604514\n"
     ]
    }
   ],
   "source": [
    "# fit a XGBoost model\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get the predictions\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# compute the mae\n",
    "mae = np.mean(np.abs(y_test - y_hat))\n",
    "\n",
    "# compute the mean percentage error\n",
    "percentage_error = np.mean(100*np.abs((y_test - y_hat) / y_test))\n",
    "\n",
    "print(mae)\n",
    "print(percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 61ms/step - loss: 9529.0703 - mae: 95.7070 - val_loss: 9911.1758 - val_mae: 98.6251\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9413.0283 - mae: 95.0958 - val_loss: 9724.5254 - val_mae: 97.6727\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9180.1504 - mae: 93.8590 - val_loss: 9358.8301 - val_mae: 95.7784\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8697.2891 - mae: 91.2676 - val_loss: 8624.9902 - val_mae: 91.8606\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7765.0288 - mae: 85.9637 - val_loss: 7238.7290 - val_mae: 83.9645\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6009.0005 - mae: 74.9440 - val_loss: 4871.8999 - val_mae: 68.5947\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3421.8848 - mae: 55.9977 - val_loss: 1709.7942 - val_mae: 40.4868\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 892.0654 - mae: 24.0638 - val_loss: 255.8599 - val_mae: 10.3505\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1081.6134 - mae: 26.4405 - val_loss: 590.6405 - val_mae: 20.3142\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 793.1156 - mae: 20.6915 - val_loss: 197.0796 - val_mae: 9.1018\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 502.2543 - mae: 17.2489 - val_loss: 471.6458 - val_mae: 19.6581\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 656.3220 - mae: 20.9590 - val_loss: 388.1305 - val_mae: 17.3758\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 512.4430 - mae: 17.5278 - val_loss: 188.3764 - val_mae: 9.4674\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 469.6534 - mae: 15.9271 - val_loss: 144.2831 - val_mae: 7.6434\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 455.8696 - mae: 15.2291 - val_loss: 136.8090 - val_mae: 7.3510\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 382.4589 - mae: 14.8266 - val_loss: 152.5634 - val_mae: 8.2861\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 417.4128 - mae: 14.9958 - val_loss: 149.1022 - val_mae: 8.2904\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 392.0818 - mae: 14.8217 - val_loss: 132.3734 - val_mae: 7.5586\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 314.3831 - mae: 13.8703 - val_loss: 123.7233 - val_mae: 7.3045\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 343.1456 - mae: 14.1062 - val_loss: 122.9891 - val_mae: 7.4021\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 277.3619 - mae: 12.8482 - val_loss: 112.4315 - val_mae: 7.0878\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 275.3452 - mae: 12.3731 - val_loss: 121.3742 - val_mae: 7.6397\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 292.9894 - mae: 12.8632 - val_loss: 123.6194 - val_mae: 7.9623\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 309.3188 - mae: 13.3272 - val_loss: 101.3881 - val_mae: 6.9357\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 309.1498 - mae: 12.7655 - val_loss: 91.9366 - val_mae: 6.6450\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 270.1366 - mae: 12.5970 - val_loss: 104.0477 - val_mae: 7.3899\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 350.7611 - mae: 14.4736 - val_loss: 110.4720 - val_mae: 7.8470\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 301.7359 - mae: 13.7697 - val_loss: 80.7887 - val_mae: 6.3132\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 268.3647 - mae: 12.1973 - val_loss: 80.0390 - val_mae: 6.3742\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 295.4186 - mae: 12.6443 - val_loss: 97.8177 - val_mae: 7.4520\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 264.9810 - mae: 12.3045 - val_loss: 96.4785 - val_mae: 7.4655\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 283.8788 - mae: 13.3591 - val_loss: 72.0157 - val_mae: 6.1833\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 249.3307 - mae: 12.4104 - val_loss: 73.6963 - val_mae: 6.3501\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 235.4954 - mae: 11.7892 - val_loss: 70.3709 - val_mae: 6.2466\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 211.0653 - mae: 11.3424 - val_loss: 64.2699 - val_mae: 5.9406\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 224.5974 - mae: 11.2369 - val_loss: 67.8689 - val_mae: 6.2242\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 304.0850 - mae: 13.3515 - val_loss: 66.7187 - val_mae: 6.1975\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 238.0186 - mae: 11.7735 - val_loss: 60.7537 - val_mae: 5.8810\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 218.2684 - mae: 11.4808 - val_loss: 73.6165 - val_mae: 6.6699\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 215.6801 - mae: 11.6520 - val_loss: 87.8516 - val_mae: 7.5474\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 237.3996 - mae: 12.4760 - val_loss: 62.0908 - val_mae: 6.0659\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 261.5200 - mae: 13.2100 - val_loss: 63.1279 - val_mae: 6.2458\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 206.8503 - mae: 10.9390 - val_loss: 73.8092 - val_mae: 6.8955\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 236.4223 - mae: 11.7063 - val_loss: 66.1028 - val_mae: 6.4835\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 195.5896 - mae: 10.8805 - val_loss: 61.6498 - val_mae: 6.1973\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 210.1686 - mae: 10.6590 - val_loss: 58.2453 - val_mae: 5.9625\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 195.5126 - mae: 10.9357 - val_loss: 57.0308 - val_mae: 5.9285\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 217.5001 - mae: 10.8643 - val_loss: 80.0090 - val_mae: 7.3621\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 210.3693 - mae: 11.1449 - val_loss: 52.1107 - val_mae: 5.6368\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 186.8263 - mae: 10.3590 - val_loss: 52.9816 - val_mae: 5.5809\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 209.2318 - mae: 11.1404 - val_loss: 83.4978 - val_mae: 7.5667\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 221.2872 - mae: 11.4130 - val_loss: 60.2715 - val_mae: 6.3887\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 232.1019 - mae: 11.5503 - val_loss: 53.2854 - val_mae: 5.7617\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 219.5459 - mae: 11.2594 - val_loss: 86.3697 - val_mae: 7.7525\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 210.6010 - mae: 11.4023 - val_loss: 55.5762 - val_mae: 6.1635\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 177.5075 - mae: 10.3306 - val_loss: 51.6297 - val_mae: 5.7682\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 213.0443 - mae: 10.8889 - val_loss: 59.1382 - val_mae: 6.3209\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 236.5977 - mae: 12.2523 - val_loss: 78.7938 - val_mae: 7.3803\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 229.5475 - mae: 11.9915 - val_loss: 55.0699 - val_mae: 6.0200\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 191.0357 - mae: 10.8718 - val_loss: 63.0104 - val_mae: 6.4217\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 210.1559 - mae: 10.9971 - val_loss: 66.2823 - val_mae: 6.5186\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 203.4109 - mae: 11.1403 - val_loss: 58.7556 - val_mae: 6.0563\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 223.9885 - mae: 11.5600 - val_loss: 65.2294 - val_mae: 6.3686\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 212.6558 - mae: 11.2768 - val_loss: 67.0249 - val_mae: 6.5877\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 181.9594 - mae: 10.2012 - val_loss: 56.9427 - val_mae: 5.9404\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 201.0293 - mae: 10.7982 - val_loss: 54.2811 - val_mae: 5.8160\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 195.4413 - mae: 10.8751 - val_loss: 59.8866 - val_mae: 6.3200\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 183.0307 - mae: 10.0316 - val_loss: 52.0768 - val_mae: 5.7778\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 186.4268 - mae: 10.2222 - val_loss: 48.6778 - val_mae: 5.5032\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 237.9205 - mae: 12.2930 - val_loss: 47.3680 - val_mae: 5.3610\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 179.8040 - mae: 10.5176 - val_loss: 51.1494 - val_mae: 5.7837\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 182.9597 - mae: 10.3243 - val_loss: 48.8392 - val_mae: 5.5939\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 189.4449 - mae: 10.0877 - val_loss: 49.1668 - val_mae: 5.6261\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 198.5350 - mae: 10.9969 - val_loss: 46.5591 - val_mae: 5.3525\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 228.2756 - mae: 11.6373 - val_loss: 50.9600 - val_mae: 5.9339\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 196.4893 - mae: 10.9097 - val_loss: 53.0033 - val_mae: 6.1457\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 188.4194 - mae: 10.4226 - val_loss: 43.0393 - val_mae: 5.1896\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 180.7408 - mae: 10.4224 - val_loss: 54.2015 - val_mae: 6.2679\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 164.0125 - mae: 9.5797 - val_loss: 65.4760 - val_mae: 6.8557\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 175.6290 - mae: 9.9993 - val_loss: 42.9201 - val_mae: 5.2114\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 191.3142 - mae: 10.4465 - val_loss: 46.7543 - val_mae: 5.5483\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 169.4807 - mae: 9.9962 - val_loss: 67.4356 - val_mae: 6.9214\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 176.6325 - mae: 9.8822 - val_loss: 53.6647 - val_mae: 5.9101\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 209.6911 - mae: 11.1104 - val_loss: 59.6648 - val_mae: 6.2597\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 205.9145 - mae: 10.6219 - val_loss: 57.0090 - val_mae: 6.0873\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 158.1861 - mae: 9.2525 - val_loss: 91.3463 - val_mae: 8.0376\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 175.5067 - mae: 10.1945 - val_loss: 54.2068 - val_mae: 5.9835\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 181.5898 - mae: 10.3628 - val_loss: 51.8066 - val_mae: 5.8578\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 159.3977 - mae: 9.7238 - val_loss: 71.8251 - val_mae: 7.1588\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 168.7240 - mae: 9.7538 - val_loss: 63.3869 - val_mae: 6.7290\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 182.3341 - mae: 10.0169 - val_loss: 45.5494 - val_mae: 5.5382\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 197.2625 - mae: 10.7695 - val_loss: 47.7662 - val_mae: 5.7324\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 218.8324 - mae: 10.9715 - val_loss: 86.4432 - val_mae: 7.9363\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 170.8964 - mae: 9.6277 - val_loss: 43.0969 - val_mae: 5.2832\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 153.5327 - mae: 9.0565 - val_loss: 41.5079 - val_mae: 5.0379\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 175.9511 - mae: 10.0588 - val_loss: 51.0922 - val_mae: 5.8463\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 195.2311 - mae: 10.8578 - val_loss: 67.7867 - val_mae: 6.8848\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 155.5517 - mae: 9.2007 - val_loss: 43.5677 - val_mae: 5.1875\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 197.3914 - mae: 10.5433 - val_loss: 82.4636 - val_mae: 7.6623\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 193.6140 - mae: 10.1939 - val_loss: 57.9702 - val_mae: 6.3091\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "7.543370198393387\n",
      "9.354396681533608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n",
      "C:\\Users\\jakub\\AppData\\Local\\Temp/ipykernel_25756/3771872762.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# fit a neural network model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Resizing, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# turn X_train bool to integers\n",
    "boolean_columns = [col for col in X_train.columns if X_train[col].dtype == bool]\n",
    "\n",
    "for col in boolean_columns:\n",
    "    X_train[col] = X_train[col].astype(int) \n",
    " \n",
    "\n",
    "# fit the model on the X_train and y_train\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation=\"relu\", input_dim=X_train.shape[1]))  # More complex first layer\n",
    "model.add(Dropout(0.3))  # Dropout to reduce overfitting\n",
    "model.add(Dense(128, activation=\"relu\"))  # Second layer\n",
    "model.add(Dropout(0.2))  # Additional Dropout layer\n",
    "model.add(Dense(64, activation=\"relu\"))  # Third layer\n",
    "model.add(Dense(32, activation=\"relu\"))  # Fourth layer\n",
    "model.add(Dropout(0.1))  # Dropout layer\n",
    "model.add(Dense(16, activation=\"relu\"))  # New additional layer\n",
    "model.add(Dense(1)) \n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# get the predictions\n",
    "boolean_columns = [col for col in X_test.columns if X_test[col].dtype == bool]\n",
    "for col in boolean_columns:\n",
    "    X_test[col] = X_test[col].astype(int)\n",
    "\n",
    "y_hat = model.predict(X_test).flatten()\n",
    "\n",
    "# compute the mae\n",
    "mae = np.mean(np.abs(y_test - y_hat))\n",
    "\n",
    "# compute the mean percentage error\n",
    "percentage_error = np.mean(100*np.abs((y_test - y_hat) / y_test))\n",
    "\n",
    "print(mae)\n",
    "print(percentage_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
